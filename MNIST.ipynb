{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "utb_vMI2_-jq"
      },
      "source": [
        "import torch, torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FWAp8PqoEEz"
      },
      "source": [
        "%%capture\n",
        "!pip install captum\n",
        "from captum.attr import DeepLift, IntegratedGradients\n",
        "!pip install torchsummary\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "batch_size = 128\n",
        "num_epochs = 12"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUjAcBlAcX86"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hzIfmZKOc80"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(p=0.3),\n",
        "        )\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(12*12*64, 50),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(50, 10),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(-1, 12*12*64)\n",
        "        x = self.fc_layers(x)\n",
        "        return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58r9t9-lWv_P"
      },
      "source": [
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # print(data.shape, type(data))\n",
        "        output = model(data)\n",
        "        # print(output.shape, type(output))\n",
        "        loss = F.nll_loss(output.log(), target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output.log(), target).item() # sum up batch loss\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index in [1] of the max log-probability (max, max_index)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5atCZu5ZWppF"
      },
      "source": [
        "%%capture\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('mnist_data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor()\n",
        "                   ])),\n",
        "    batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('mnist_data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor()\n",
        "                   ])),\n",
        "    batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Jd_ll2lMFet"
      },
      "source": [
        "model = Net().to(device)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHhNVH7yhTZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d4b6ea-2626-4a04-d816-e1a46e61d79e"
      },
      "source": [
        "summary(model, input_size=(1,28,28))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             320\n",
            "              ReLU-2           [-1, 32, 26, 26]               0\n",
            "            Conv2d-3           [-1, 64, 24, 24]          18,496\n",
            "              ReLU-4           [-1, 64, 24, 24]               0\n",
            "         MaxPool2d-5           [-1, 64, 12, 12]               0\n",
            "           Dropout-6           [-1, 64, 12, 12]               0\n",
            "            Linear-7                   [-1, 50]         460,850\n",
            "              ReLU-8                   [-1, 50]               0\n",
            "           Dropout-9                   [-1, 50]               0\n",
            "           Linear-10                   [-1, 10]             510\n",
            "          Softmax-11                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 480,176\n",
            "Trainable params: 480,176\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.03\n",
            "Params size (MB): 1.83\n",
            "Estimated Total Size (MB): 2.87\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KuD1by0ze8A",
        "outputId": "022d25a5-5290-4603-d0cd-4aefeb10fa63"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhoJzQXYI7m5"
      },
      "source": [
        "model = Net().to(device)\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/model12.pt\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.7)\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\\"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqHA15fLg0Gr"
      },
      "source": [
        "examples = enumerate(test_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "Captum_DeepLIFT = DeepLift(model)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIBko9mGOs6d"
      },
      "source": [
        "example_data, example_targets = example_data.cuda(), example_targets.cuda()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp6_DtWg_Qni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9680c49e-7367-4943-eb6b-b3662fc04ab3"
      },
      "source": [
        "image = example_data[0]\n",
        "image.requires_grad_()\n",
        "\n",
        "attribution = Captum_DeepLIFT.attribute(image.unsqueeze(0), target=example_targets[0])\n",
        "attribution = attribution.cpu()\n",
        "attribution.detach()\n",
        "attribution = attribution[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/captum/attr/_core/deep_lift.py:323: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
            "               activations. The hooks and attributes will be removed\n",
            "            after the attribution is finished\n",
            "  after the attribution is finished\"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "cMzqCN2GbWWx",
        "outputId": "dfe269bf-2cc1-4c61-9498-2f36ddff7a80"
      },
      "source": [
        "# attribution.shape\n",
        "# print(example_targets[0])\n",
        "# tensor_image.permute(1, 2, 0)\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('DeepLIFT black')\n",
        "plt.axis('off')\n",
        "plt.imshow(attribution[0].detach().numpy(), cmap='gray', interpolation='none')\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.title('original:{}'.format(example_targets[0]))\n",
        "plt.axis('off')\n",
        "plt.imshow(image[0].cpu().detach().numpy(), cmap='gray', interpolation='none')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "fig.savefig('out.png', dpi=100)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: tight_layout not applied: number of columns in subplot specifications must be multiples of one another.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgznNEyytmMB"
      },
      "source": [
        "# use .cuda(), .cpu() on tensor to get in new location"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO8ZZbRHvDiH"
      },
      "source": [
        "# num_steps = 50\n",
        "# step_sizes = torch.linspace(0, 1, steps=num_steps+1)\n",
        "# device = torch.device('cpu')\n",
        "# @torch.jit.script\n",
        "def interpolation_points(base, final, n):\n",
        "    base_interp = base.unsqueeze(0)\n",
        "    final_interp = final.unsqueeze(0)\n",
        "    steps = torch.linspace(0, 1, steps=n, device=base.device)\n",
        "    for _ in range(base.ndim):\n",
        "        steps = steps.unsqueeze(-1)\n",
        "    return base_interp+(final_interp-base_interp)*steps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYH_SaMfu-cP"
      },
      "source": [
        "fig = plt.figure(figsize=(20, 20))\n",
        "sample = data[0][0]\n",
        "baseline = torch.zeros_like(sample)\n",
        "i = 0\n",
        "# for alpha, image in zip(alphas[0::10], interpolated_images[0::10]):\n",
        "interpolated_images = interpolation_points(baseline, sample, 10)\n",
        "outputs = model(interpolated_images)\n",
        "print(outputs.shape)\n",
        "for image in interpolated_images:\n",
        "  i += 1\n",
        "  plt.subplot(1, 10+1, i)\n",
        "  plt.title(f'alpha: {(i-1)/10:.1f}')\n",
        "  plt.imshow(image, vmin=0, vmax=1)\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}